{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40e3b533add5c85d66d7987325df519e90205f5c"
   },
   "source": [
    "The aim of this kernel is to detect hate speech (racist/sexist) in tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d40962c3e7eb81e99b016a45cbb6feb833d02957"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b77e64eeb8e12f930065e5c058aef60f4db39f4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0ecbffbb1689a2878fcc9f58ea5a8ef3a48b08b"
   },
   "outputs": [],
   "source": [
    "train  = pd.read_csv(\"../input/train_E6oV3lV.csv\")\n",
    "test = pd.read_csv(\"../input/test_tweets_anuFYb8.csv\")\n",
    "train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3900cb2fbd40a995bb2d638c252e4f8c9b3212be"
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e067c11955935f698f665f0cce89e3b643c80a4f"
   },
   "outputs": [],
   "source": [
    "df = train.append(test, ignore_index = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85e8e4848d223da56c7b3bacf9a46a38fb8ea019"
   },
   "source": [
    "Remove twitter handlers i.e., @user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd576fb0e23772de113e06a7ad33c0b1b8d1b98b"
   },
   "outputs": [],
   "source": [
    "train['cleaned_tweet'] = train.tweet.apply(lambda x: ' '.join([word for word in x.split() if not word.startswith('@')]))\n",
    "test['cleaned_tweet'] = test.tweet.apply(lambda x: ' '.join([word for word in x.split() if not word.startswith('@')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90a1e47a1f5bda41ee89ab644b0fd7c2e0a1aabc"
   },
   "source": [
    "### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "350721643bb4ff356dda8632b7ec9e0dcffaef3d"
   },
   "outputs": [],
   "source": [
    "#Select all words from normal tweet\n",
    "normal_words = ' '.join([word for word in train['cleaned_tweet'][train['label'] == 0]])\n",
    "#Collect all hashtags\n",
    "pos_htag = [htag for htag in normal_words.split() if htag.startswith('#')]\n",
    "#Remove hashtag symbol (#)\n",
    "pos_htag = [pos_htag[i][1:] for i in range(len(pos_htag))]\n",
    "#Count frequency of each word\n",
    "pos_htag_freqcount = nltk.FreqDist(pos_htag)\n",
    "pos_htag_df = pd.DataFrame({'Hashtag' : list(pos_htag_freqcount.keys()),\n",
    "                            'Count' : list(pos_htag_freqcount.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "018c93071768685990def7f74ae288bd238f979e"
   },
   "outputs": [],
   "source": [
    "#Select top 20 most frequent hashtags and plot them   \n",
    "most_frequent = pos_htag_df.nlargest(columns=\"Count\", n = 20) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=most_frequent, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a50731fa0c6dd78f37276f7b9dab578c7374d463"
   },
   "outputs": [],
   "source": [
    "#Repeat same steps for negative tweets\n",
    "negative_words = ' '.join([word for word in train['cleaned_tweet'][train['label'] == 1]])\n",
    "neg_htag = [htag for htag in negative_words.split() if htag.startswith('#')]\n",
    "neg_htag = [neg_htag[i][1:] for i in range(len(neg_htag))]\n",
    "neg_htag_freqcount = nltk.FreqDist(neg_htag)\n",
    "neg_htag_df = pd.DataFrame({'Hashtag' : list(neg_htag_freqcount.keys()),\n",
    "                            'Count' : list(neg_htag_freqcount.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6dd897bfb0be4b836f37f6df3b391cc561e9213"
   },
   "outputs": [],
   "source": [
    "most_frequent = neg_htag_df.nlargest(columns=\"Count\", n = 20) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=most_frequent, x= \"Hashtag\", y = \"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a8176d7edcd0189735892a03fa02400aa2b51ff"
   },
   "source": [
    "From both plots, we can conclude that hashtags are very important for sentiment analysis and should not be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1d1c111b9c7535d4e88fc533af23a92f55c6edd"
   },
   "source": [
    "## Finding common words in both classes of tweets using Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7f6bb72628f3919bb9ca9d945ea8a30dd375156"
   },
   "source": [
    "### Normal Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ccfdaa674f997f54d7e63d4c7de7162ec595f5c"
   },
   "outputs": [],
   "source": [
    "normal_words = ' '.join([word for word in train['cleaned_tweet'][train['label'] == 0]])\n",
    "wordcloud = WordCloud(width = 800, height = 500, max_font_size = 110).generate(normal_words)\n",
    "print('Normal words')\n",
    "plt.figure(figsize= (12,8))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f1845295ee69f4e667862cf3265401a0c391ec8"
   },
   "source": [
    "### Racist/Sexist Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0aca5caccd2902f015f32f43accb6936d3bd5e91"
   },
   "outputs": [],
   "source": [
    "negative_words = ' '.join([word for word in train['cleaned_tweet'][train['label'] == 1]])\n",
    "wordcloud = WordCloud(width = 800, height = 500, max_font_size = 110).generate(negative_words)\n",
    "print('Negative words')\n",
    "plt.figure(figsize= (12,8))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf58a8a9f2f660fc25922612caebbb0ac64093b3"
   },
   "source": [
    "Words used like love, friend, happy are used in normal tweets whereas racist/sexist can be found in words like trump, black, politics etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e0853100203d8a90d1f93f282c89fdce53592e0"
   },
   "outputs": [],
   "source": [
    "train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8582542c7c3a554f86272e4e888749558ab5a3a3"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train['cleaned_tweet'], train['label'], random_state = 0)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84f426e28891e0a03d8b10a94fe3a896f240819b"
   },
   "source": [
    "## Applying Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5146351649030c32e49a28c8f90925b020e4cf3"
   },
   "source": [
    "Rescale data using CountVectorizer\n",
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec38f8465b508e95533030f356ca5115c2c34a35"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25120a9f4820e6e889c16042f5d6d85f43e37c68"
   },
   "outputs": [],
   "source": [
    "print('Total features =', len(vect.get_feature_names()))\n",
    "print(vect.get_feature_names()[::5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9adbae4a7a0b03da68b690bc9d345c3e756f1e9c"
   },
   "outputs": [],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d865737112c5fd86faa8fd18fd8f6a9885c1c1b9"
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a561b33942167ff23ff52fbe7e11454bd84e97cd"
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "pred = model.predict(vect.transform(X_val))\n",
    "print('F1 :', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5acf6d41ce735a4c80244f860f170fee1a0de5c"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a49787843f896f2e33d2079518e91cd072068d6"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "pred = model.predict(vect.transform(X_val))\n",
    "print('F1 :', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "596e7b8005aa0afb57fea55e0def7fc793946189"
   },
   "source": [
    "Logistic Regression performed well then Naive Bayes for the default parameters. Thus, we will be using only Logistic Regression ahead.\n",
    "\n",
    "Lets now rescale the data using tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "803004ff4379e5e419e63217bfa6e023aa6b7c71"
   },
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0929c79069eaedde4a0a87adea99d541d80c98b"
   },
   "outputs": [],
   "source": [
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer().fit(X_train)\n",
    "print('Total Features =', len(vect.get_feature_names()))\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "pred = model.predict(vect.transform(X_val))\n",
    "print('F1: ', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11e17e42e74d0c2a8812f853bb5e660d570173b4"
   },
   "source": [
    "tf-idf not performed well for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33fcd55e83d605bb8c01f1a261abb685744aa38b"
   },
   "source": [
    "## Bag-of-Words with more than one word (n-grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66b2261150dd46c0011d3df33ef5fea2b539ed04"
   },
   "source": [
    "### min_df & n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24b45f48591bbbba22918e6d590d0483ff44d6d4"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 2, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "print('Total Features =', len(vect.get_feature_names()))\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "pred = model.predict(vect.transform(X_val))\n",
    "print('F1: ', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e92ba4d6381fe7aa8a78e4a16ab708a99e91d3c0"
   },
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48c21ac47019a1eee91bc2d070b60661f099cd87"
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "param_grid = {\"logisticregression__C\": [0.01, 0.1, 1, 10, 50, 100],\n",
    "              \"countvectorizer__min_df\": [1,2,3],\n",
    "              \"countvectorizer__ngram_range\": [(1,1), (1,2), (1,3)]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv = 5, scoring = 'f1', n_jobs = -1)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best parameters:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9532a2dc6357677b1c7177d7a506197aefd73f93"
   },
   "source": [
    "OOPS!!! For this dataset, our default parameters were the best except fot our model (C = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c1c1734d2d5986fa851135e2545f978411e8d4e"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 1, ngram_range = (1,1)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "print('Total Features =', len(vect.get_feature_names()))\n",
    "\n",
    "model = LogisticRegression(C = 10)\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "pred = model.predict(vect.transform(X_val))\n",
    "print('F1: ', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39af142c2725634af14fbb50b0e42d3bf5e8fd43"
   },
   "outputs": [],
   "source": [
    "print('Fraction of racist/sexist tweet in train data :', train.label.sum()/len(train))\n",
    "print('Fraction of racist/sexist tweet predicted by model :', pred.sum()/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64e99c5d15fad8d2e8d370783e6c739acee40120"
   },
   "source": [
    "Fraction is very less. Lets change the default predict probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2e696c2bca094aeb0bb82bc23de7d62ca171cfd"
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(vect.transform(X_val))\n",
    "pred = np.where(pred_prob[:,1] > 0.35, 1, 0)\n",
    "print('Fraction of racist/sexist tweet predicted by model :', sum(pred)/len(pred))\n",
    "print('F1: ', f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30106d2bc595814f8b689fc6bf9739d3a3e28133"
   },
   "source": [
    "Using hyperparameter tuning and probability method, we were able to improve our model score by 5%.\n",
    "\n",
    "Lets look at largest and smallest coefficients that our model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "808b024ead427604cb06890be027bb34b7bb8fc9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest_coefs :\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest_coefs :\\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca8c8a9ee089bc1cc9060ea8d360056fed6a20cf"
   },
   "source": [
    "The smallest coefficients are indicating to normal tweets to the model whereas the largest coeeficients are indicative for racist/sexist tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "193c66701d62cac8aebd35e5ec52b83a80500252"
   },
   "outputs": [],
   "source": [
    "X_test = test['tweet']\n",
    "test_pred = model.predict_proba(vect.transform(X_test))\n",
    "predictions = np.where(test_pred[:,1] > 0.35, 1, 0)\n",
    "results = pd.DataFrame(data = {'id' : test.id, 'label' : predictions})\n",
    "#results.to_csv('results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
